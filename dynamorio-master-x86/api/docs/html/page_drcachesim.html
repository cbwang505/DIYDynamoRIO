<!-- HTML header for doxygen 1.8.16-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.16"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<title>DynamoRIO API: Cache Simulator</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">DynamoRIO API
   </div>
  </td>
   <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.16 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('page_drcachesim.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Cache Simulator </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><code>drcachesim</code> is a DynamoRIO client that collects memory access traces and feeds them to either an online or offline tool for analysis. The default analysis tool is a CPU cache simulator, while other provided tools compute metrics such as reuse distance. The trace collector and simulator support multiple processes each with multiple threads. The analysis tool framework is extensible, supporting the creation of new tools which can operate both online and offline.</p>
<ul>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim">Overview</a></li>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim_run">Running the Simulator</a></li>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim_tools">Analysis Tool Suite</a></li>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim_config_file">Configuration File</a></li>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim_offline">Offline Traces and Analysis</a></li>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim_partial">Tracing a Subset of Execution</a></li>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim_sim">Simulator Details</a></li>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim_analyzer">Cache Miss Analyzer</a></li>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim_phys">Physical Addresses</a></li>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim_core">Core Simulation Support</a></li>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim_extend">Extending the Simulator</a></li>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim_tracer">Customizing the Tracer</a></li>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim_funcs">Tracing Function Calls</a></li>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim_newtool">Creating New Analysis Tools</a></li>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim_ops">Simulator Parameters</a></li>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim_limit">Current Limitations</a></li>
<li><a class="el" href="page_drcachesim.html#sec_drcachesim_cmp">Comparison to Other Simulators</a></li>
</ul>
<h1><a class="anchor" id="sec_drcachesim"></a>
Overview</h1>
<p><code>drcachesim</code> consists of two components: a tracer and an analyzer. The tracer collects a memory access trace from each thread within each application process. The analyzer consumes the traces (online or offline) and performs customized analysis. It is designed to be extensible, allowing users to easily implement a simulator for different devices, such as CPU caches, TLBs, page caches, etc. (see <a class="el" href="page_drcachesim.html#sec_drcachesim_extend">Extending the Simulator</a>), or to build arbitrary trace analysis tools (see <a class="el" href="page_drcachesim.html#sec_drcachesim_newtool">Creating New Analysis Tools</a>). The default analyzer simulates the architectural behavior of caching devices for a target application (or multiple applications).</p>
<h1><a class="anchor" id="sec_drcachesim_run"></a>
Running the Simulator</h1>
<p>To launch <code>drcachesim</code>, use the <code>-t</code> flag to <code>drrun:</code> </p>
<div class="fragment"><div class="line">$ bin64/drrun -t drcachesim -- /path/to/target/app &lt;args&gt; &lt;<span class="keywordflow">for</span>&gt; &lt;app&gt;</div>
</div><!-- fragment --><p>The target application will be launched under a DynamoRIO tracer client that gathers all of its memory references and passes them to the simulator via a pipe. (See <a class="el" href="page_drcachesim.html#sec_drcachesim_offline">Offline Traces and Analysis</a> for how to dump a trace for offline analysis.) Any child processes will be followed into and profiled, with their memory references passed to the simulator as well.</p>
<p>Here is an example:</p>
<div class="fragment"><div class="line">$ bin64/drrun -t drcachesim -- ~/test/pi_estimator</div>
<div class="line">Estimation of pi is 3.142425985001098</div>
<div class="line">---- &lt;application exited with code 0&gt; ----</div>
<div class="line">Cache simulation results:</div>
<div class="line">Core #0 (1 thread(s))</div>
<div class="line">  L1I stats:</div>
<div class="line">    Hits:                          258,433</div>
<div class="line">    Misses:                          1,148</div>
<div class="line">    Miss rate:                        0.44%</div>
<div class="line">  L1D stats:</div>
<div class="line">    Hits:                           93,654</div>
<div class="line">    Misses:                          2,624</div>
<div class="line">    Prefetch hits:                     458</div>
<div class="line">    Prefetch misses:                 2,166</div>
<div class="line">    Miss rate:                        2.73%</div>
<div class="line">Core #1 (1 thread(s))</div>
<div class="line">  L1I stats:</div>
<div class="line">    Hits:                            8,895</div>
<div class="line">    Misses:                             99</div>
<div class="line">    Miss rate:                        1.10%</div>
<div class="line">  L1D stats:</div>
<div class="line">    Hits:                            3,448</div>
<div class="line">    Misses:                            156</div>
<div class="line">    Prefetch hits:                      26</div>
<div class="line">    Prefetch misses:                   130</div>
<div class="line">    Miss rate:                        4.33%</div>
<div class="line">Core #2 (1 thread(s))</div>
<div class="line">  L1I stats:</div>
<div class="line">    Hits:                            4,150</div>
<div class="line">    Misses:                            101</div>
<div class="line">    Miss rate:                        2.38%</div>
<div class="line">  L1D stats:</div>
<div class="line">    Hits:                            1,578</div>
<div class="line">    Misses:                            130</div>
<div class="line">    Prefetch hits:                      25</div>
<div class="line">    Prefetch misses:                   105</div>
<div class="line">    Miss rate:                        7.61%</div>
<div class="line">Core #3 (0 thread(s))</div>
<div class="line">LL stats:</div>
<div class="line">    Hits:                            1,414</div>
<div class="line">    Misses:                          2,844</div>
<div class="line">    Prefetch hits:                     824</div>
<div class="line">    Prefetch misses:                 1,577</div>
<div class="line">    Local miss rate:                 66.79%</div>
<div class="line">    Child hits:                    370,667</div>
<div class="line">    Total miss rate:                  0.76%</div>
</div><!-- fragment --><h1><a class="anchor" id="sec_drcachesim_tools"></a>
Analysis Tool Suite</h1>
<p>In addition to a CPU cache simulator, other analysis tools are available that operate on memory address traces. Which tool is used can be selected with the <code>-simulator_type</code> parameter.</p>
<p>To simulate TLB devices instead of caches, pass <code>TLB</code> to <code>-simulator_type:</code> </p>
<div class="fragment"><div class="line">$ bin64/drrun -t drcachesim -simulator_type TLB -- ~/test/pi_estimator</div>
<div class="line">Estimation of pi is 3.142425985001098</div>
<div class="line">---- &lt;application exited with code 0&gt; ----</div>
<div class="line">TLB simulation results:</div>
<div class="line">Core #0 (1 thread(s))</div>
<div class="line">  L1I stats:</div>
<div class="line">    Hits:                          252,412</div>
<div class="line">    Misses:                            401</div>
<div class="line">    Miss rate:                        0.16%</div>
<div class="line">  L1D stats:</div>
<div class="line">    Hits:                           87,132</div>
<div class="line">    Misses:                          9,127</div>
<div class="line">    Miss rate:                        9.48%</div>
<div class="line">  LL stats:</div>
<div class="line">    Hits:                            9,315</div>
<div class="line">    Misses:                            213</div>
<div class="line">    Local miss rate:                  2.24%</div>
<div class="line">    Child hits:                    339,544</div>
<div class="line">    Total miss rate:                  0.06%</div>
<div class="line">Core #1 (1 thread(s))</div>
<div class="line">  L1I stats:</div>
<div class="line">    Hits:                            8,709</div>
<div class="line">    Misses:                             20</div>
<div class="line">    Miss rate:                        0.23%</div>
<div class="line">  L1D stats:</div>
<div class="line">    Hits:                            3,544</div>
<div class="line">    Misses:                             55</div>
<div class="line">    Miss rate:                        1.53%</div>
<div class="line">  LL stats:</div>
<div class="line">    Hits:                               15</div>
<div class="line">    Misses:                             60</div>
<div class="line">    Local miss rate:                 80.00%</div>
<div class="line">    Child hits:                     12,253</div>
<div class="line">    Total miss rate:                  0.49%</div>
<div class="line">Core #2 (1 thread(s))</div>
<div class="line">  L1I stats:</div>
<div class="line">    Hits:                            1,622</div>
<div class="line">    Misses:                             21</div>
<div class="line">    Miss rate:                        1.28%</div>
<div class="line">  L1D stats:</div>
<div class="line">    Hits:                              689</div>
<div class="line">    Misses:                             35</div>
<div class="line">    Miss rate:                        4.83%</div>
<div class="line">  LL stats:</div>
<div class="line">    Hits:                                3</div>
<div class="line">    Misses:                             53</div>
<div class="line">    Local miss rate:                 94.64%</div>
<div class="line">    Child hits:                      2,311</div>
<div class="line">    Total miss rate:                  2.24%</div>
<div class="line">Core #3 (0 thread(s))</div>
</div><!-- fragment --><p>To compute reuse distance metrics:</p>
<div class="fragment"><div class="line">$ bin64/drrun -t drcachesim -simulator_type reuse_distance -reuse_distance_histogram -- ~/test/pi_estimator</div>
<div class="line">Estimation of pi is 3.142425985001098</div>
<div class="line">---- &lt;application exited with code 0&gt; ----</div>
<div class="line">Reuse distance tool aggregated results:</div>
<div class="line">Total accesses: 349632</div>
<div class="line">Unique accesses: 196603</div>
<div class="line">Unique cache lines accessed: 4235</div>
<div class="line"> </div>
<div class="line">Reuse distance mean: 14.64</div>
<div class="line">Reuse distance median: 1</div>
<div class="line">Reuse distance standard deviation: 104.10</div>
<div class="line">Reuse distance histogram:</div>
<div class="line">Distance       Count  Percent  Cumulative</div>
<div class="line">       0      153029   44.36%   44.36%</div>
<div class="line">       1      101294   29.37%   73.73%</div>
<div class="line">       2       14116    4.09%   77.82%</div>
<div class="line">       3       14248    4.13%   81.95%</div>
<div class="line">       4        8894    2.58%   84.53%</div>
<div class="line">       5        2733    0.79%   85.32%</div>
<div class="line">...</div>
<div class="line">==================================================</div>
<div class="line">Reuse distance tool results <span class="keywordflow">for</span> shard 29327 (thread 29327):</div>
<div class="line">Total accesses: 335084</div>
<div class="line">Unique accesses: 187927</div>
<div class="line">Unique cache lines accessed: 4148</div>
<div class="line"> </div>
<div class="line">Reuse distance mean: 14.77</div>
<div class="line">Reuse distance median: 1</div>
<div class="line">Reuse distance standard deviation: 106.02</div>
<div class="line">Reuse distance histogram:</div>
<div class="line">Distance       Count  Percent  Cumulative</div>
<div class="line">       0      147157   44.47%   44.47%</div>
<div class="line">       1       96820   29.26%   73.72%</div>
<div class="line">       2       13613    4.11%   77.84%</div>
<div class="line">       3       13834    4.18%   82.02%</div>
<div class="line">       4        8666    2.62%   84.64%</div>
<div class="line">       5        2552    0.77%   85.41%</div>
<div class="line">...</div>
<div class="line">    3658          29    0.01%  100.00%</div>
<div class="line">    3851           1    0.00%  100.00%</div>
<div class="line"> </div>
<div class="line">Reuse distance threshold = 100 cache lines</div>
<div class="line">Top 10 frequently referenced cache lines</div>
<div class="line">        cache line:     #references   #distant refs</div>
<div class="line">    0x7f2a86b3fd80:        27980,            0</div>
<div class="line">    0x7f2a86b3fdc0:        18823,            0</div>
<div class="line">    0x7f2a88388fc0:        16409,          111</div>
<div class="line">    0x7f2a8838abc0:        15176,            6</div>
<div class="line">    0x7f2a883884c0:         9930,           20</div>
<div class="line">    0x7f2a88388480:         7944,           20</div>
<div class="line">    0x7f2a88388500:         7574,           20</div>
<div class="line">    0x7f2a88398d00:         7390,          100</div>
<div class="line">    0x7f2a86b3fd40:         6668,            0</div>
<div class="line">    0x7f2a88388440:         5717,           20</div>
<div class="line">Top 10 distant repeatedly referenced cache lines</div>
<div class="line">        cache line:     #references   #distant refs</div>
<div class="line">    0x7f2a885a4180:          246,          132</div>
<div class="line">    0x7f2a87504ec0:          202,          128</div>
<div class="line">    0x7f2a875044c0:          323,          126</div>
<div class="line">    0x7f2a885a4480:          220,          126</div>
<div class="line">    0x7f2a87504f00:          293,          124</div>
<div class="line">    0x7f2a86fd7e00:          289,          124</div>
<div class="line">    0x7f2a875049c0:          221,          124</div>
<div class="line">    0x7f2a875053c0:          270,          122</div>
<div class="line">    0x7f2a86db9c00:          269,          122</div>
<div class="line">    0x7f2a875047c0:          201,          122</div>
<div class="line"> </div>
<div class="line">==================================================</div>
<div class="line">Reuse distance tool results <span class="keywordflow">for</span> shard 29328 (thread 29328):</div>
<div class="line">Total accesses: 12216</div>
<div class="line">Unique accesses: 7251</div>
<div class="line">Unique cache lines accessed: 319</div>
<div class="line"> </div>
<div class="line">Reuse distance mean: 12.98</div>
<div class="line">Reuse distance median: 1</div>
<div class="line">Reuse distance standard deviation: 38.19</div>
<div class="line">Reuse distance histogram:</div>
<div class="line">Distance       Count  Percent  Cumulative</div>
<div class="line">       0        4965   41.73%   41.73%</div>
<div class="line">       1        3758   31.59%   73.32%</div>
<div class="line">       2         411    3.45%   76.78%</div>
<div class="line">       3         348    2.93%   79.70%</div>
<div class="line">       4         179    1.50%   81.21%</div>
<div class="line">       5         152    1.28%   82.48%</div>
<div class="line">...</div>
</div><!-- fragment --><p>A reuse time tool is also provided, which counts the total number of memory accesses (without considering uniqueness) between accesses to the same address:</p>
<div class="fragment"><div class="line">$ bin64/drrun -t drcachesim -simulator_type reuse_time -- ~/test/pi_estimator</div>
<div class="line">Estimation of pi is 3.142425985001098</div>
<div class="line">---- &lt;application exited with code 0&gt; ----</div>
<div class="line">Reuse time tool aggregated results:</div>
<div class="line">Total accesses: 88281</div>
<div class="line">Total instructions: 261315</div>
<div class="line">Mean reuse time: 433.47</div>
<div class="line">Reuse time histogram:</div>
<div class="line">Distance       Count  Percent  Cumulative</div>
<div class="line">       1       27893   32.84%      32.84%</div>
<div class="line">       2       10948   12.89%      45.73%</div>
<div class="line">       3        5789    6.82%      52.54%</div>
<div class="line">...</div>
<div class="line">==================================================</div>
<div class="line">Reuse time tool results <span class="keywordflow">for</span> shard 29482 (thread 29482):</div>
<div class="line">Total accesses: 84194</div>
<div class="line">Total instructions: 250854</div>
<div class="line">Mean reuse time: 450.01</div>
<div class="line">Reuse time histogram:</div>
<div class="line">Distance       Count  Percent  Cumulative</div>
<div class="line">       1       26677   32.86%      32.86%</div>
<div class="line">       2       10508   12.95%      45.81%</div>
<div class="line">       3        5427    6.69%      52.50%</div>
<div class="line">...</div>
<div class="line">==================================================</div>
<div class="line">Reuse time tool results <span class="keywordflow">for</span> shard 29483 (thread 29483):</div>
<div class="line">Total accesses: 3411</div>
<div class="line">Total instructions: 8805</div>
<div class="line">Mean reuse time: 86.36</div>
<div class="line">Reuse time histogram:</div>
<div class="line">Distance       Count  Percent  Cumulative</div>
<div class="line">       1        1014   31.56%      31.56%</div>
<div class="line">       2         363   11.30%      42.86%</div>
<div class="line">       3         308    9.59%      52.44%</div>
</div><!-- fragment --><p>To simply see the counts of instructions and memory references broken down by thread use the basic counts tool:</p>
<div class="fragment"><div class="line">$ bin64/drrun -t drcachesim -simulator_type basic_counts -- ~/test/pi_estimator</div>
<div class="line">Estimation of pi is 3.142425985001098</div>
<div class="line">---- &lt;application exited with code 0&gt; ----</div>
<div class="line">Basic counts tool results:</div>
<div class="line">Total counts:</div>
<div class="line">      267193 total (fetched) instructions</div>
<div class="line">         345 total non-fetched instructions</div>
<div class="line">           0 total prefetches</div>
<div class="line">       67686 total data loads</div>
<div class="line">       22503 total data stores</div>
<div class="line">           3 total threads</div>
<div class="line">         280 total scheduling markers</div>
<div class="line">           0 total transfer markers</div>
<div class="line">           0 total other markers</div>
<div class="line">Thread 247451 counts:</div>
<div class="line">      255009 (fetched) instructions</div>
<div class="line">         345 non-fetched instructions</div>
<div class="line">           0 prefetches</div>
<div class="line">       64453 data loads</div>
<div class="line">       21243 data stores</div>
<div class="line">         258 scheduling markers</div>
<div class="line">           0 transfer markers</div>
<div class="line">           0 other markers</div>
<div class="line">Thread 247453 counts:</div>
<div class="line">        9195 (fetched) instructions</div>
<div class="line">           0 non-fetched instructions</div>
<div class="line">           0 prefetches</div>
<div class="line">        2444 data loads</div>
<div class="line">         937 data stores</div>
<div class="line">          12 scheduling markers</div>
<div class="line">           0 transfer markers</div>
<div class="line">           0 other markers</div>
<div class="line">Thread 247454 counts:</div>
<div class="line">        2989 (fetched) instructions</div>
<div class="line">           0 non-fetched instructions</div>
<div class="line">           0 prefetches</div>
<div class="line">         789 data loads</div>
<div class="line">         323 data stores</div>
<div class="line">          10 scheduling markers</div>
<div class="line">           0 transfer markers</div>
<div class="line">           0 other markers</div>
</div><!-- fragment --><p>The non-fetched instructions are x86 string loop instructions, where subsequent iterations do not incur a fetch. They are included in the trace as a different type of trace entry to support core simulators in addition to cache simulators.</p>
<p>The opcode_mix tool uses the non-fetched instruction information along with the preserved libraries and binaries from the traced execution to gather more information on each executed instruction than was stored in the trace. It only supports offline traces, and the <code>modules.log</code> file created during post-processing of the trace must be preserved. The results are broken down by the opcodes used in DR's IR, where <code>mov</code> is split into a separate opcode for load and store but both have the same public string "mov":</p>
<div class="fragment"><div class="line">$ bin64/drrun -t drcachesim -offline -- ~/test/pi_estimator</div>
<div class="line">Estimation of pi is 3.142425985001098</div>
<div class="line">$ bin64/drrun -t drcachesim -simulator_type opcode_mix -indir drmemtrace.*.dir</div>
<div class="line">Opcode mix tool results:</div>
<div class="line">         267271 : total executed instructions</div>
<div class="line">          36432 :       mov</div>
<div class="line">          31075 :       mov</div>
<div class="line">          24715 :       add</div>
<div class="line">          22579 :      test</div>
<div class="line">          22539 :       cmp</div>
<div class="line">          12137 :       lea</div>
<div class="line">          11136 :       jnz</div>
<div class="line">          10568 :     movzx</div>
<div class="line">          10243 :        jz</div>
<div class="line">           9056 :       and</div>
<div class="line">           8064 :       jnz</div>
<div class="line">           7279 :        jz</div>
<div class="line">           5659 :      push</div>
<div class="line">           4528 :       sub</div>
<div class="line">           4357 :       pop</div>
<div class="line">           4001 :       shr</div>
<div class="line">           3427 :      jnbe</div>
<div class="line">           2634 :       mov</div>
<div class="line">           2469 :       shl</div>
<div class="line">           2344 :        jb</div>
<div class="line">           2291 :       ret</div>
<div class="line">           2178 :       xor</div>
<div class="line">           2164 :      call</div>
<div class="line">           2111 :   pcmpeqb</div>
<div class="line">           1472 :    movdqa</div>
<div class="line">...</div>
</div><!-- fragment --><p>The view tool prints out disassembled instructions in att, intel, arm or DR format for offline traces. The -skip_refs and -sim_refs flags can be used to set a start point and end point for the disassembled view. Note that these flags compute the number of instructions which are skipped or displayed which is distinct from the number of trace entries.</p>
<p>The tool also displays metadata marker entries for timestamps, on which core and thread the subsequent instruction sequence was executed, and kernel and system call transfers (these correspond to signal or event handler interruptions of the regular execution flow).</p>
<div class="fragment"><div class="line">$ bin64/drrun -t drcachesim -simulator_type view -sim_refs 20 -indir drmemtrace.*.dir</div>
<div class="line">&lt;marker: timestamp 13218166936578899&gt;</div>
<div class="line">&lt;marker: tid 46977 on core 7&gt;</div>
<div class="line">  0x00007f3a5127d870  48 83 ec 48          sub    $0x48, %rsp</div>
<div class="line">  0x00007f3a5127d874  0f 31                rdtsc</div>
<div class="line">  0x00007f3a5127d876  48 c1 e2 20          shl    $0x20, %rdx</div>
<div class="line">  0x00007f3a5127d87a  89 c0                mov    %eax, %eax</div>
<div class="line">  0x00007f3a5127d87c  48 09 c2             or     %rax, %rdx</div>
<div class="line">  0x00007f3a5127d87f  48 8b 05 ea 25 22 00 mov    &lt;rel&gt; 0x00007f3a5149fe70, %rax</div>
<div class="line">  0x00007f3a5127d886  48 89 15 d3 23 22 00 mov    %rdx, &lt;rel&gt; 0x00007f3a5149fc60</div>
<div class="line">  0x00007f3a5127d88d  48 8d 15 dc 25 22 00 lea    &lt;rel&gt; 0x00007f3a5149fe70, %rdx</div>
<div class="line">  0x00007f3a5127d894  49 89 d6             mov    %rdx, %r14</div>
<div class="line">  0x00007f3a5127d897  4c 2b 35 62 27 22 00 sub    &lt;rel&gt; 0x00007f3a514a0000, %r14</div>
<div class="line">  0x00007f3a5127d89e  48 85 c0             test   %rax, %rax</div>
<div class="line">  0x00007f3a5127d8a1  48 89 15 40 31 22 00 mov    %rdx, &lt;rel&gt; 0x00007f3a514a09e8</div>
<div class="line">  0x00007f3a5127d8a8  4c 89 35 29 31 22 00 mov    %r14, &lt;rel&gt; 0x00007f3a514a09d8</div>
<div class="line">  0x00007f3a5127d8af  0f 84 9b 00 00 00    jz     $0x00007f3a5127d950</div>
<div class="line">  0x00007f3a5127d8b5  4c 8d 05 84 27 22 00 lea    &lt;rel&gt; 0x00007f3a514a0040, %r8</div>
<div class="line">  0x00007f3a5127d8bc  49 b9 d8 03 00 80 03 mov    $0x00000003800003d8, %r9</div>
<div class="line">                      00 00 00</div>
<div class="line">  0x00007f3a5127d8c6  48 b9 78 fb ff 7f 03 mov    $0x000000037ffffb78, %rcx</div>
<div class="line">                      00 00 00</div>
<div class="line">  0x00007f3a5127d8d0  48 8d 35 41 31 22 00 lea    &lt;rel&gt; 0x00007f3a514a0a18, %rsi</div>
<div class="line">  0x00007f3a5127d8d7  bf ff ff ff 6f       mov    $0x6fffffff, %edi</div>
<div class="line">  0x00007f3a5127d8dc  41 bb ff fd ff 6f    mov    $0x6ffffdff, %r11d</div>
<div class="line">View tool results:</div>
<div class="line">             20 : total disassembled instructions</div>
</div><!-- fragment --><p>Here is an example of a signal handler interrupting the regular flow:</p>
<div class="fragment"><div class="line">  0x00007fa87c6c0512  eb 5a                jmp    $0x00007fa87c6c056e</div>
<div class="line">  0x00007fa87c6c056e  80 bd 7c ff ff ff 00 cmp    -0x84(%rbp), $0x00</div>
<div class="line">  0x00007fa87c6c0575  0f 85 e5 03 00 00    jnz    $0x00007fa87c6c0960</div>
<div class="line">&lt;marker: kernel xfer to handler&gt;</div>
<div class="line">&lt;marker: timestamp 13218875821472138&gt;</div>
<div class="line">&lt;marker: tid 159754 on core 0&gt;</div>
<div class="line">  0x00007fa879bb88dc  55                   push   %rbp</div>
<div class="line">  0x00007fa879bb88dd  48 89 e5             mov    %rsp, %rbp</div>
<div class="line">  0x00007fa879bb88e0  48 83 ec 40          sub    $0x40, %rsp</div>
<div class="line">  0x00007fa879bb88e4  89 7d dc             mov    %edi, -0x24(%rbp)</div>
<div class="line">  0x00007fa879bb88e7  48 89 75 d0          mov    %rsi, -0x30(%rbp)</div>
<div class="line">  0x00007fa879bb88eb  48 89 55 c8          mov    %rdx, -0x38(%rbp)</div>
<div class="line">  0x00007fa879bb88ef  83 7d dc 0a          cmp    -0x24(%rbp), $0x0a</div>
<div class="line">  0x00007fa879bb88f3  74 0e                jz     $0x00007fa879bb8903</div>
<div class="line">  0x00007fa879bb8903  48 8b 45 c8          mov    -0x38(%rbp), %rax</div>
<div class="line">  0x00007fa879bb8907  48 83 c0 28          add    $0x28, %rax</div>
<div class="line">  0x00007fa879bb890b  48 89 45 f8          mov    %rax, -0x08(%rbp)</div>
<div class="line">  0x00007fa879bb890f  48 8b 45 f8          mov    -0x08(%rbp), %rax</div>
<div class="line">  0x00007fa879bb8913  48 8b 80 80 00 00 00 mov    0x80(%rax), %rax</div>
<div class="line">  0x00007fa879bb891a  48 89 45 f0          mov    %rax, -0x10(%rbp)</div>
<div class="line">  0x00007fa879bb891e  eb 6d                jmp    $0x00007fa879bb898d</div>
<div class="line">  0x00007fa879bb898d  90                   nop</div>
<div class="line">  0x00007fa879bb898e  c9                   leave</div>
<div class="line">  0x00007fa879bb898f  c3                   ret</div>
<div class="line">  0x00007fa87c6ca3a0  48 c7 c0 0f 00 00 00 mov    $0x0000000f, %rax</div>
<div class="line">  0x00007fa87c6ca3a7  0f 05                syscall</div>
<div class="line">&lt;marker: timestamp 13218875821472148&gt;</div>
<div class="line">&lt;marker: tid 159754 on core 0&gt;</div>
<div class="line">&lt;marker: syscall xfer&gt;</div>
<div class="line">&lt;marker: timestamp 13218875821475975&gt;</div>
<div class="line">&lt;marker: tid 159754 on core 4&gt;</div>
<div class="line">  0x00007fa87c6c057b  48 8b 75 c8          mov    -0x38(%rbp), %rsi</div>
<div class="line">  0x00007fa87c6c057f  64 48 33 34 25 28 00 xor    %fs:0x28, %rsi</div>
<div class="line">                      00 00</div>
</div><!-- fragment --><p>The func_view tool records function argument and return values for function names specified at tracing time. See <a class="el" href="page_drcachesim.html#sec_drcachesim_funcs">Tracing Function Calls</a> for more information.</p>
<div class="fragment"><div class="line">$ bin64/drrun -t drcachesim -offline -record_function <span class="stringliteral">&#39;fib|1&#39;</span> -- ~/test/fib 5</div>
<div class="line">Estimation of pi is 3.142425985001098</div>
<div class="line">$ bin64/drrun -t drcachesim -simulator_type func_view -indir drmemtrace.*.dir</div>
<div class="line">0x7fc06d2288eb =&gt; common.fib!fib(0x5)</div>
<div class="line">    0x7fc06d22888e =&gt; common.fib!fib(0x4)</div>
<div class="line">        0x7fc06d22888e =&gt; common.fib!fib(0x3)</div>
<div class="line">            0x7fc06d22888e =&gt; common.fib!fib(0x2)</div>
<div class="line">                0x7fc06d22888e =&gt; common.fib!fib(0x1) =&gt; 0x1</div>
<div class="line">                0x7fc06d22889d =&gt; common.fib!fib(0x0) =&gt; 0x1</div>
<div class="line">            =&gt; 0x2</div>
<div class="line">            0x7fc06d22889d =&gt; common.fib!fib(0x1) =&gt; 0x1</div>
<div class="line">        =&gt; 0x3</div>
<div class="line">        0x7fc06d22889d =&gt; common.fib!fib(0x2)</div>
<div class="line">            0x7fc06d22888e =&gt; common.fib!fib(0x1) =&gt; 0x1</div>
<div class="line">            0x7fc06d22889d =&gt; common.fib!fib(0x0) =&gt; 0x1</div>
<div class="line">        =&gt; 0x2</div>
<div class="line">    =&gt; 0x5</div>
<div class="line">    0x7fc06d22889d =&gt; common.fib!fib(0x3)</div>
<div class="line">        0x7fc06d22888e =&gt; common.fib!fib(0x2)</div>
<div class="line">            0x7fc06d22888e =&gt; common.fib!fib(0x1) =&gt; 0x1</div>
<div class="line">            0x7fc06d22889d =&gt; common.fib!fib(0x0) =&gt; 0x1</div>
<div class="line">        =&gt; 0x2</div>
<div class="line">        0x7fc06d22889d =&gt; common.fib!fib(0x1) =&gt; 0x1</div>
<div class="line">    =&gt; 0x3</div>
<div class="line">=&gt; 0x8</div>
<div class="line">Function view tool results:</div>
<div class="line">Function <span class="keywordtype">id</span>=0: common.fib!fib</div>
<div class="line">       15 calls</div>
<div class="line">       15 returns</div>
</div><!-- fragment --><p>The top referenced cache lines are displayed by the <code>histogram</code> tool:</p>
<div class="fragment"><div class="line">$ bin64/drrun -t drcachesim -simulator_type histogram -- ~/test/pi_estimator</div>
<div class="line">Estimation of pi is 3.142425985001098</div>
<div class="line">---- &lt;application exited with code 0&gt; ----</div>
<div class="line">Cache line histogram tool results:</div>
<div class="line">icache: 1134 unique cache lines</div>
<div class="line">dcache: 3062 unique cache lines</div>
<div class="line">icache top 10</div>
<div class="line">    0x7facdd013780: 30929</div>
<div class="line">    0x7facdb789fc0: 27664</div>
<div class="line">    0x7facdb78a000: 18629</div>
<div class="line">    0x7facdd003e80: 18176</div>
<div class="line">    0x7facdd003500: 11121</div>
<div class="line">    0x7facdd0034c0: 9763</div>
<div class="line">    0x7facdd005940: 8865</div>
<div class="line">    0x7facdd003480: 8277</div>
<div class="line">    0x7facdb789f80: 6660</div>
<div class="line">    0x7facdd003540: 5888</div>
<div class="line">dcache top 10</div>
<div class="line">    0x7ffcc35e7d80: 4088</div>
<div class="line">    0x7ffcc35e7d40: 3497</div>
<div class="line">    0x7ffcc35e7e00: 3478</div>
<div class="line">    0x7ffcc35e7f40: 2919</div>
<div class="line">    0x7ffcc35e7dc0: 2837</div>
<div class="line">    0x7facdbe2e980: 2452</div>
<div class="line">    0x7facdbe2ec80: 2273</div>
<div class="line">    0x7ffcc35e7e80: 2194</div>
<div class="line">    0x7facdb6625c0: 2016</div>
<div class="line">    0x7ffcc35e7e40: 1997</div>
</div><!-- fragment --><h1><a class="anchor" id="sec_drcachesim_config_file"></a>
Configuration File</h1>
<p><code>drcachesim</code> supports reconfigurable cache hierarchies defined in a configuration file. The configuration file is a text file with the following formatting rules.</p>
<ul>
<li>A comment starts with two slashes followed by one or more spaces. Anything after the '// ' until the end of the line is considered a comment and ignored.</li>
<li>A parameter's name and its value are listed consecutively with white space (spaces, tabs, or a new line) between them.</li>
<li>Parameters must be separated by white space. Including one parameter per line helps keep the configuration file more human-readable.</li>
<li>A cache's parameters must be enclosed inside braces and preceded by the cache's user-chosen unique name.</li>
<li>Parameters can be listed in any order.</li>
<li>Parameters not included in the configuration file take their default values.</li>
<li>String values must not be enclosed in quotations.</li>
</ul>
<p>Supported common parameters and their value types (each of these parameters sets the corresponding option with the same name described in <a class="el" href="page_drcachesim.html#sec_drcachesim_ops">Simulator Parameters</a>):</p><ul>
<li>num_cores &lt;unsigned int&gt;</li>
<li>line_size &lt;unsigned int&gt;</li>
<li>skip_refs &lt;unsigned int&gt;</li>
<li>warmup_refs &lt;unsigned int&gt;</li>
<li>warmup_fraction &lt;float in [0,1]&gt;</li>
<li>sim_refs &lt;unsigned int&gt;</li>
<li>cpu_scheduling &lt;bool&gt;</li>
<li>verbose &lt;unsigned int&gt;</li>
<li>coherence &lt;bool&gt;</li>
</ul>
<p>Supported cache parameters and their value types:</p><ul>
<li>type &lt;string, one of "instruction", "data", or "unified"&gt;</li>
<li>core &lt;unsigned int in [0, num_cores)&gt;</li>
<li>size &lt;unsigned int, power of 2&gt;</li>
<li>assoc &lt;unsigned int, power of 2&gt;</li>
<li>inclusive &lt;bool&gt;</li>
<li>parent &lt;string&gt;</li>
<li>replace_policy &lt;string, one of "LRU", "LFU", or "FIFO"&gt;</li>
<li>prefetcher &lt;string, one of "nextline" or "none"&gt;</li>
<li>miss_file &lt;string&gt;</li>
</ul>
<p>Example: </p><div class="fragment"><div class="line"><span class="comment">// Configuration for a single-core CPU.</span></div>
<div class="line"> </div>
<div class="line"><span class="comment">// Common params.</span></div>
<div class="line">num_cores       1</div>
<div class="line">line_size       64</div>
<div class="line">cpu_scheduling  <span class="keyword">true</span></div>
<div class="line">sim_refs        8888888</div>
<div class="line">warmup_fraction 0.8</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Cache params.</span></div>
<div class="line">P0L1I {                        <span class="comment">// P0 L1 instruction cache</span></div>
<div class="line">  type            instruction</div>
<div class="line">  core            0</div>
<div class="line">  size            65536        <span class="comment">// 64K</span></div>
<div class="line">  assoc           8</div>
<div class="line">  parent          P0L2</div>
<div class="line">  replace_policy  LRU</div>
<div class="line">}</div>
<div class="line">P0L1D {                        <span class="comment">// P0 L1 data cache</span></div>
<div class="line">  type            data</div>
<div class="line">  core            0</div>
<div class="line">  size            65536        <span class="comment">// 64K</span></div>
<div class="line">  assoc           8</div>
<div class="line">  parent          P0L2</div>
<div class="line">  replace_policy  LRU</div>
<div class="line">}</div>
<div class="line">P0L2 {                         <span class="comment">// P0 L2 unified cache</span></div>
<div class="line">  size            512K</div>
<div class="line">  assoc           16</div>
<div class="line">  inclusive       <span class="keyword">true</span></div>
<div class="line">  parent          LLC</div>
<div class="line">  replace_policy  LRU</div>
<div class="line">}</div>
<div class="line">LLC {                          <span class="comment">// LLC</span></div>
<div class="line">  size            1M</div>
<div class="line">  assoc           16</div>
<div class="line">  inclusive       <span class="keyword">true</span></div>
<div class="line">  parent          mem</div>
<div class="line">  replace_policy  LRU</div>
<div class="line">  miss_file       misses.txt</div>
<div class="line">}</div>
</div><!-- fragment --><h1><a class="anchor" id="sec_drcachesim_offline"></a>
Offline Traces and Analysis</h1>
<p>To dump a trace for future offline analysis, use the <code>offline</code> parameter: </p><div class="fragment"><div class="line">$ bin64/drrun -t drcachesim -offline -- /path/to/target/app &lt;args&gt; &lt;<span class="keywordflow">for</span>&gt; &lt;app&gt;</div>
</div><!-- fragment --><p>The collected traces will be dumped into a newly created directory, which can be passed to drcachesim for offline cache simulation with the <code>-indir</code> option: </p><div class="fragment"><div class="line">$ bin64/drrun -t drcachesim -indir drmemtrace.app.pid.xxxx.dir/</div>
</div><!-- fragment --><p>The direct results of the <code>-offline</code> run are raw, compacted files, stored in a <code>raw/</code> subdirectory of the <code>drmemtrace.app.pid.xxxx.dir</code> directory. The <code>-indir</code> option both converts the data to a canonical trace form and passes the resulting data to the cache simulator. The canonical trace data is stored by <code>-indir</code> in a <code>trace/</code> subdirectory inside the <code>drmemtrace.app.pid.xxxx.dir/</code> directory. For both the raw and canonical data, a separate file per application thread is used. If the canonical data already exists, future runs will use that data rather than re-converting it. Either the top-level directory or the <code>trace/</code> subdirectory may be pointed at with <code>-indir:</code> </p>
<div class="fragment"><div class="line">$ bin64/drrun -t drcachesim -indir drmemtrace.app.pid.xxxx.dir/trace</div>
</div><!-- fragment --><p>The canonical trace files may be manually compressed with gzip, as the trace reader supports reading gzipped files.</p>
<p>Older versions of the simulator produced a single trace file containing all threads interleaved. The <code>-infile</code> option supports reading these legacy files: </p><div class="fragment"><div class="line">$ gzip drmemtrace.app.pid.xxxx.dir/drmemtrace.trace</div>
<div class="line">$ bin64/drrun -t drcachesim -infile drmemtrace.app.pid.xxxx.dir/drmemtrace.trace.gz</div>
</div><!-- fragment --><p>The same analysis tools used online are available for offline: the trace format is identical.</p>
<h1><a class="anchor" id="sec_drcachesim_partial"></a>
Tracing a Subset of Execution</h1>
<p>While the cache simulator supports skipping references, for large applications the overhead of the tracing itself is too high to conveniently trace the entire execution. There are several methods of tracing only during a desired window of execution.</p>
<p>The <code>-trace_after_instrs</code> option delays tracing by the specified number of dynamic instruction executions. This can be used to skip initialization and arrive at the desired starting point. The trace's length can also be limited by the <code>-exit_after_tracing</code> option.</p>
<p>If the application can be modified, it can be linked with the <code>drcachesim</code> tracer and use DynamoRIO's start/stop API routines <a class="el" href="dr__app_8h.html#ace92a2658a46bb5811ece68ae964fd62">dr_app_setup_and_start()</a> and <a class="el" href="dr__app_8h.html#a7e062573c669d8a5564abf54ebf90f31">dr_app_stop_and_cleanup()</a> to delimit the desired trace region. As an example, see <a href="https://github.com/DynamoRIO/dynamorio/blob/master/clients/drcachesim/tests/burst_static.cpp">our burst_static test application</a>.</p>
<h1><a class="anchor" id="sec_drcachesim_sim"></a>
Simulator Details</h1>
<p>Generally, the simulator is able to be extended to model a variety of caching devices. Currently, CPU caches and TLBs are implemented. The type of device to simulate can be specified by the parameter "-simulator_type" (see <a class="el" href="page_drcachesim.html#sec_drcachesim_ops">Simulator Parameters</a>).</p>
<p>The CPU cache simulator models a configurable number of cores, each with an L1 data cache and an L1 instruction cache. Currently there is a single shared L2 unified cache, but we would like to extend support to arbitrary cache hierarchies (see <a class="el" href="page_drcachesim.html#sec_drcachesim_limit">Current Limitations</a>). The cache line size and each cache's total size and associativity are user-specified (see <a class="el" href="page_drcachesim.html#sec_drcachesim_ops">Simulator Parameters</a>).</p>
<p>The TLB simulator models a configurable number of cores, each with an L1 instruction TLB, an L1 data TLB, and an L2 unified TLB. Each TLB's entry number and associativity, and the virtual/physical page size, are user-specified (see <a class="el" href="page_drcachesim.html#sec_drcachesim_ops">Simulator Parameters</a>).</p>
<p>Neither simulator has a simple way to know which core any particular thread executed on for each of its instructions. The tracer records which core a thread is on each time it writes out a full trace buffer, giving an approximation of the actual scheduling (at the granularity of the trace buffer size). By default, these cache and TLB simulators ignore that information and schedule threads to simulated cores in a static round-robin fashion with load balancing to fill in gaps with new threads after threads exit. The option "-cpu_scheduling" (see <a class="el" href="page_drcachesim.html#sec_drcachesim_ops">Simulator Parameters</a>) can be used to instead map each physical cpu to a simulated core and use the recorded cpu that each segment of thread execution occurred on to schedule execution in a manner that more closely resembles the traced execution on the physical machine. Below is an example of the output using this option running an application with many threads on a pysical machine with 8 cpus. The 8 cpus are mapped to the 4 simulated cores:</p>
<div class="fragment"><div class="line">$ bin64/drrun -t drcachesim -cpu_scheduling -- ~/test/pi_estimator 20</div>
<div class="line">Estimation of pi is 3.141592653798125</div>
<div class="line">&lt;Stopping application /home/bruening/dr/test/threadsig (213517)&gt;</div>
<div class="line">---- &lt;application exited with code 0&gt; ----</div>
<div class="line">Cache simulation results:</div>
<div class="line">Core #0 (2 traced CPU(s): #2, #5)</div>
<div class="line">  L1I stats:</div>
<div class="line">    Hits:                        2,756,429</div>
<div class="line">    Misses:                          1,190</div>
<div class="line">    Miss rate:                        0.04%</div>
<div class="line">  L1D stats:</div>
<div class="line">    Hits:                        1,747,822</div>
<div class="line">    Misses:                         13,511</div>
<div class="line">    Prefetch hits:                   2,354</div>
<div class="line">    Prefetch misses:                11,157</div>
<div class="line">    Miss rate:                        0.77%</div>
<div class="line">Core #1 (2 traced CPU(s): #4, #0)</div>
<div class="line">  L1I stats:</div>
<div class="line">    Hits:                          472,948</div>
<div class="line">    Misses:                            299</div>
<div class="line">    Miss rate:                        0.06%</div>
<div class="line">  L1D stats:</div>
<div class="line">    Hits:                          895,099</div>
<div class="line">    Misses:                          1,224</div>
<div class="line">    Prefetch hits:                     253</div>
<div class="line">    Prefetch misses:                   971</div>
<div class="line">    Miss rate:                        0.14%</div>
<div class="line">Core #2 (2 traced CPU(s): #1, #7)</div>
<div class="line">  L1I stats:</div>
<div class="line">    Hits:                          448,581</div>
<div class="line">    Misses:                            649</div>
<div class="line">    Miss rate:                        0.14%</div>
<div class="line">  L1D stats:</div>
<div class="line">    Hits:                          811,483</div>
<div class="line">    Misses:                          1,723</div>
<div class="line">    Prefetch hits:                     378</div>
<div class="line">    Prefetch misses:                 1,345</div>
<div class="line">    Miss rate:                        0.21%</div>
<div class="line">Core #3 (2 traced CPU(s): #6, #3)</div>
<div class="line">  L1I stats:</div>
<div class="line">    Hits:                          275,192</div>
<div class="line">    Misses:                            154</div>
<div class="line">    Miss rate:                        0.06%</div>
<div class="line">  L1D stats:</div>
<div class="line">    Hits:                          522,655</div>
<div class="line">    Misses:                            850</div>
<div class="line">    Prefetch hits:                     173</div>
<div class="line">    Prefetch misses:                   677</div>
<div class="line">    Miss rate:                        0.16%</div>
<div class="line">LL stats:</div>
<div class="line">    Hits:                           12,491</div>
<div class="line">    Misses:                          7,109</div>
<div class="line">    Prefetch hits:                   8,922</div>
<div class="line">    Prefetch misses:                 5,228</div>
<div class="line">    Local miss rate:                 36.27%</div>
<div class="line">    Child hits:                  7,933,367</div>
<div class="line">    Total miss rate:                  0.09%</div>
</div><!-- fragment --><p>The memory access traces contain some optimizations that combine references for one basic block together. This may result in not considering some thread interleavings that could occur natively. There are no other disruptions to thread ordering, however, and the application runs with all of its threads concurrently just like it would natively (although slower).</p>
<p>Once every process has exited, the simulator prints cache miss statistics for each cache to stderr. The simulator is designed to be extensible, allowing for different cache studies to be carried out: see <a class="el" href="page_drcachesim.html#sec_drcachesim_extend">Extending the Simulator</a>.</p>
<p>For L2 caching devices, the L1 caching devices are considered its <em>children</em>. Two separate miss rates are computed, one (the "Local miss rate") considering just requests that reach L2 while the other (the "Total miss rate") includes the child hits.</p>
<p>For memory requests that cross blocks, each block touched is considered separately, resulting in separate hit and miss statistics. This can be changed by implementing a custom statistics gatherer (see <a class="el" href="page_drcachesim.html#sec_drcachesim_extend">Extending the Simulator</a>).</p>
<p>Software and hardware prefetches are combined in the prefetch hit and miss statistics, which are reported separately from regular loads and stores. To isolate software prefetch statistics, disable the hardware prefetcher by running with "-data_prefetcher none" (see <a class="el" href="page_drcachesim.html#sec_drcachesim_ops">Simulator Parameters</a>). While misses from software prefetches are included in cache miss files, misses from hardware prefetches are not.</p>
<h1><a class="anchor" id="sec_drcachesim_analyzer"></a>
Cache Miss Analyzer</h1>
<p>The cache simulator can be used to analyze the stream of last-level cache (LLC) miss addresses. This can be useful when looking for patterns that can be utilized in software prefetching. The current analyzer can only identify simple stride patterns, but it can be extended to search for more complex patterns. To invoke the miss analyzer, pass <code>miss_analyzer</code> to the <code>-simulator_type</code> parameter. To write the prefetching hints to a file use the <code>-LL_miss_file</code> parameter to specify the file's path and name.</p>
<p>For example, to run the analyzer on a benchmark called "my_benchmark" and store the prefetching recommendations in a file called "rec.csv", run the following:</p>
<div class="fragment"><div class="line">$ bin64/drrun -t drcachesim -simulator_type miss_analyzer -LL_miss_file rec.csv -- my_benchmark</div>
</div><!-- fragment --><h1><a class="anchor" id="sec_drcachesim_phys"></a>
Physical Addresses</h1>
<p>The memory access tracing client gathers virtual addresses. On Linux, if the kernel allows user-mode applications access to the <code>/proc/self/pagemap</code> file, physical addresses may be used instead. This can be requested via the <code>-use_physical</code> runtime option (see <a class="el" href="page_drcachesim.html#sec_drcachesim_ops">Simulator Parameters</a>). This works on current kernels but is expected to stop working from user mode on future kernels due to recent security changes (see <a href="http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=ab676b7d6fbf4b294bf198fb27ade5b0e865c7ce">http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=ab676b7d6fbf4b294bf198fb27ade5b0e865c7ce</a>).</p>
<h1><a class="anchor" id="sec_drcachesim_core"></a>
Core Simulation Support</h1>
<p>The <code>drcachesim</code> trace format includes information intended for use by core simulators as well as pure cache simulators. For traces that are not filtered by an online first-level cache, each data reference is preceded by the instruction fetch entry for the instruction that issued the data request. Additionally, on x86, string loop instructions involve a single insruction fetch followed by a loop of loads and/or stores. A <code>drcachesim</code> trace includes a special "no-fetch" instruction entry per iteration so that core simulators have the instruction information to go along with each load and store, while cache simulators can ignore these "no-fetch" entries and avoid incorrectly inflating instruction fetch statistics.</p>
<p>Offline traces guarantee that a branch target instruction entry in a trace must immediately follow the branch instruction with no intervening thread switch. This allows a core simulator to identify the target of a branch by looking at the subsequent trace entry. However, this guarantee does not hold when a kernel event such as a signal is delivered immediately after a branch.</p>
<p>Traces include scheduling markers providing the timestamp and hardware thread identifier on each thread transition, allowing a simulator to more closely match the actual hardware if so desired.</p>
<p>Traces also include markers indicating disruptions in user mode control flow such as signal handler entry and exit.</p>
<p>A final feature that aids core simulators is the pair of interfaces <a class="el" href="classmodule__mapper__t.html#ad58566855786b3b63cf6a05cfb496653">module_mapper_t::get_loaded_modules()</a> and <a class="el" href="classmodule__mapper__t.html#add0cc122b72c75d519971cde9eeffd87">module_mapper_t::find_mapped_trace_address()</a>, which facilitate reading the raw bytes for each instruction in order to obtain the opcode and full operand information.</p>
<h1><a class="anchor" id="sec_drcachesim_extend"></a>
Extending the Simulator</h1>
<p>The <code>drcachesim</code> tool was designed to be extensible, allowing users to easily model different caching devices, implement different models, and gather custom statistics.</p>
<p>To model different caching devices, subclass the <code>simulator_t</code>, caching_device_t, caching_device_block_t, caching_device_stats_t classes.</p>
<p>To implement a different cache model, subclass the <code>cache_t</code> class and override the <code>request()</code>, <code>access_update()</code>, and/or <code>replace_which_way()</code> method(s).</p>
<p>Statistics gathering is separated out into the <code>caching_device_stats_t</code> class. To implement custom statistics, subclass <code>caching_device_stats_t</code> and override the <code>access()</code>, <code>child_access()</code>, <code>flush()</code>, and/or <code>print_stats()</code> methods.</p>
<h1><a class="anchor" id="sec_drcachesim_tracer"></a>
Customizing the Tracer</h1>
<p>The tracer supports customization for special-purpose i/o via <a class="el" href="drmemtrace_8h.html#abb7be083ae67d4a389be1eb1c5fe1b6e">drmemtrace_replace_file_ops()</a>, allowing traces to be written to locations not supported by simple UNIX file operations. One option for using this function is to create a new client which links with the provided drmemtrace_static library, includes the <code><a class="el" href="drmemtrace_8h.html" title="Header for customizing the DrMemtrace tracer.">drmemtrace/drmemtrace.h</a></code> header via:</p>
<div class="fragment"><div class="line">use_DynamoRIO_drmemtrace_tracer(mytool)</div>
</div><!-- fragment --><p>And includes its own <a class="el" href="dr__api_8h.html#a2b938c98dd186cc94eef6880f9e3c3e9">dr_client_main()</a> which calls <a class="el" href="drmemtrace_8h.html#ab21913507ae5665dd43fd24a20cbf03c">drmemtrace_client_main()</a>.</p>
<p>The tracer also supports storing custom data with each module (i.e., library or executable) such as a build identifier via <a class="el" href="drmemtrace_8h.html#a30ea474fd519a00de470c139c53caf03">drmemtrace_custom_module_data()</a>. The custom data may be retrieved by creating a custom offline trace post-processor and using the <a class="el" href="classmodule__mapper__t.html">module_mapper_t</a> class.</p>
<h1><a class="anchor" id="sec_drcachesim_funcs"></a>
Tracing Function Calls</h1>
<p>The tracer supports recording argument and return values for specified functions. This feature is currently limited to offline mode only (<a class="el" href="page_drcachesim.html#sec_drcachesim_offline">Offline Traces and Analysis</a>). The -record_function parameter lists which function names to trace. Requested names will be located per library and each instance traced separately. The number of arguments to record is specified for each name, using a bar character to separate them. An ampersand separates functions. Here is an example:</p>
<div class="fragment"><div class="line">$ bin64/drrun -t drcachesim -offline -record_function <span class="stringliteral">&#39;fib|1&amp;calloc|2&#39;</span></div>
</div><!-- fragment --><p>Within the trace, each function is identified by a numeric identifier. The list of recorded functions, each with its identifier, is placed into a file "funclist.log" in the trace directory, where the sample tool <code>func_view</code> uses it to provide a linear function call trace as well as summary statistics as shown above.</p>
<p>The -record_heap parameter requests recording of a pre-determined set of functions related to heap allocation. The -record_heap_value paramter controls the contents of this set.</p>
<h1><a class="anchor" id="sec_drcachesim_newtool"></a>
Creating New Analysis Tools</h1>
<p><code>drcachesim</code> provides a <code>drmemtrace</code> analysis tool framework to make it easy to create new trace analysis tools. A new tool should subclass <a class="el" href="classanalysis__tool__t.html">analysis_tool_t</a>.</p>
<p>Concurrent processing of traces is supported by logically splitting a trace into "shards" which are each processed sequentially. The default shard is a traced application thread, but the tool interface can support other divisions. For tools that support concurrent processing of shards and do not need to see a single time-sorted interleaved merged trace, the interface functions with the parallel_ prefix should be overridden, and parallel_shard_supported() should return true. parallel_shard_init() will be invoked for each shard prior to invoking parallel_shard_memref() for each entry in that shard; the data structure returned from parallel_shard_init() will be passed to parallel_shard_memref() for each trace entry for that shard. The concurrency model used guarantees that all entries from any one shard are processed by the same single worker thread, so no synchronization is needed inside the parallel_ functions. A single worker thread invokes print_results() as well.</p>
<p>For serial operation, process_memref(), operates on a trace entry in a single, sorted, interleaved stream of trace entries. In the default mode of operation, the <a class="el" href="classanalyzer__t.html">analyzer_t</a> class iterates over the trace and calls the process_memref() function of each tool. An alternative mode is supported which exposes the iterator and allows a separate control infrastructure to be built. This alternative mode does not support parallel operation at this time.</p>
<p>Both parallel and serial operation can be supported by a tool, typically by having process_memref() create data on a newly seen traced thread and invoking parallel_shard_memref() to do its work.</p>
<p>For both parallel and serial operation, the function print_results() should be overridden. It is called just once after processing all trace data and it should present the results of the analysis. For parallel operation, any desired aggregation across the whole trace should occur here as well, while shard-specific results can be presented in parallel_shard_exit().</p>
<p>Today, parallel analysis is only supported for offline traces. Support for online traces may be added in the future.</p>
<p>In the default mode of operation, the <a class="el" href="classanalyzer__t.html">analyzer_t</a> class iterates over the trace and calls the appropriate <a class="el" href="classanalysis__tool__t.html">analysis_tool_t</a> functions for each tool. An alternative mode is supported which exposes the iterator and allows a separate control infrastructure to be built.</p>
<p>Each trace entry is of type <a class="el" href="memref_8h.html#adf34086351ea99fd7164ac601aa70a52">memref_t</a> and represents one instruction or data reference or a metadata operation such as a thread exit or marker. There are built-in scheduling markers providing the timestamp and cpu identifier on each thread transition. Other built-in markers indicate disruptions in user mode control flow such as signal handler entry and exit.</p>
<p>CMake support is provided for including the headers and linking the libraries of the <code>drmemtrace</code> framework. A new CMake function is defined in the DynamoRIO package which sets the include directory for using the <code>drmemtrace/</code> headers:</p>
<div class="fragment"><div class="line">use_DynamoRIO_drmemtrace(mytool)</div>
</div><!-- fragment --><p>The <code>drmemtrace_analyzer</code> library exported by the DynamoRIO package is the main library to link when building a new tool. The tools described above are also exported as the libraries <code>drmemtrace_basic_counts</code>, <code>drmemtrace_view</code>, <code>drmemtrace_opcode_mix</code>, <code>drmemtrace_histogram</code>, <code>drmemtrace_reuse_distance</code>, <code>drmemtrace_reuse_time</code>, <code>drmemtrace_simulator</code>, and <code>drmemtrace_func_view</code> and can be created using the <a class="el" href="basic__counts__create_8h.html#a5226888f7abaf6332c8f5b91d943d1ef">basic_counts_tool_create()</a>, <a class="el" href="opcode__mix__create_8h.html#a2b82af47e05133143073d6c6968039f5">opcode_mix_tool_create()</a>, <a class="el" href="histogram__create_8h.html#ad7362677ef5655e034fdc1ce994842cb">histogram_tool_create()</a>, <a class="el" href="reuse__distance__create_8h.html#aa86cae7bab3e68a22c32dd9cc586a6f8">reuse_distance_tool_create()</a>, <a class="el" href="reuse__time__create_8h.html#a92d248f0be3b49715628424e5cf87ffb">reuse_time_tool_create()</a>, <a class="el" href="view__create_8h.html#ab58a2c94598ac982114ae6181ec594cb">view_tool_create()</a>, <a class="el" href="cache__simulator__create_8h.html#a4131299a08b18510acbea8a2772d914c">cache_simulator_create()</a>, <a class="el" href="tlb__simulator__create_8h.html#a95b0db93858738f814ccddb453ba1f53">tlb_simulator_create()</a>, and func_view_create() functions.</p>
<h1><a class="anchor" id="sec_drcachesim_ops"></a>
Simulator Parameters</h1>
<p><code>drcachesim's</code> behavior can be controlled through options passed after the <code>-c</code> <code>drcachesim</code> but prior to the "--" delimiter on the command line:</p>
<div class="fragment"><div class="line">$ bin64/drrun -t drcachesim &lt;options&gt; &lt;to&gt; &lt;drcachesim&gt; -- /path/to/target/app &lt;args&gt; &lt;<span class="keywordflow">for</span>&gt; &lt;app&gt;</div>
</div><!-- fragment --><p>Boolean options can be disabled using a "-no_" prefix.</p>
<p>The parameters available are described below:</p>
<ul>
<li><b>-offline</b> <br  />
<em>default value: false</em> <br  />
By default, traces are processed online, sent over a pipe to a simulator. If this option is enabled, trace data is instead written to files in -outdir for later offline analysis. No simulator is executed.</li>
<li><b>-ipc_name</b> <br  />
<em>default value: drcachesimpipe</em> <br  />
For online tracing and simulation (the default, unless -offline is requested), specifies the name of the named pipe used to communicate between the target application processes and the caching device simulator. On Linux this can include an absolute path (if it doesn't, a default temp directory will be used). A unique name must be chosen for each instance of the simulator being run at any one time. On Windows, the name is limited to 247 characters.</li>
<li><b>-outdir</b> <br  />
<em>default value: .</em> <br  />
For the offline analysis mode (when -offline is requested), specifies the path to a directory where per-thread trace files will be written.</li>
<li><b>-subdir_prefix</b> <br  />
<em>default value: drmemtrace</em> <br  />
For the offline analysis mode (when -offline is requested), specifies the prefix for the name of the sub-directory where per-thread trace files will be written. The sub-directory is created inside -outdir and has the form 'prefix.app-name.pid.id.dir'.</li>
<li><b>-indir</b> <br  />
<em>default value: ""</em> <br  />
After a trace file is produced via -offline into -outdir, it can be passed to the simulator via this flag pointing at the subdirectory created in -outdir. The -offline tracing produces raw data files which are converted into final trace files on the first execution with -indir. The raw files can also be manually converted using the drraw2trace tool. Legacy single trace files with all threads interleaved into one are not supported with this option: use -infile instead.</li>
<li><b>-infile</b> <br  />
<em>default value: ""</em> <br  />
Directs the simulator to use a single all-threads-interleaved-into-one trace file. This is a legacy file format that is no longer produced.</li>
<li><b>-jobs</b> <br  />
<em>default value: -1</em> <br  />
By default, both post-processing of offline raw trace files and analysis of trace files is parallelized. This option controls the number of concurrent jobs. 0 disables concurrency and uses a single thread to perform all operations. A negative value sets the job count to the number of hardware threads, with a cap of 16.</li>
<li><b>-module_file</b> <br  />
<em>default value: ""</em> <br  />
The opcode_mix tool needs the modules.log file (generated by the offline post-processing step in the raw/ subdirectory) in addition to the trace file. If the file is named modules.log and is in the same directory as the trace file, or a raw/ subdirectory below the trace file, this parameter can be omitted.</li>
<li><b>-funclist_file</b> <br  />
<em>default value: ""</em> <br  />
The func_view tool needs the mapping from function name to identifier that was recorded during offline tracing. This data is stored in its own separate file in the raw/ subdirectory. If the file is named funclist.log and is in the same directory as the trace file, or a raw/ subdirectory below the trace file, this parameter can be omitted.</li>
<li><b>-cores</b> <br  />
<em>default value: 4</em> <br  />
Specifies the number of cores to simulate.</li>
<li><b>-line_size</b> <br  />
<em>default value: 64</em> <br  />
Specifies the cache line size, which is assumed to be identical for L1 and L2 caches. Must be a power of 2.</li>
<li><b>-L1I_size</b> <br  />
<em>default value: 32K</em> <br  />
Specifies the total size of each L1 instruction cache. Must be a power of 2 and a multiple of -line_size.</li>
<li><b>-L1D_size</b> <br  />
<em>default value: 32K</em> <br  />
Specifies the total size of each L1 data cache. Must be a power of 2 and a multiple of -line_size.</li>
<li><b>-L1I_assoc</b> <br  />
<em>default value: 8</em> <br  />
Specifies the associativity of each L1 instruction cache. Must be a power of 2.</li>
<li><b>-L1D_assoc</b> <br  />
<em>default value: 8</em> <br  />
Specifies the associativity of each L1 data cache. Must be a power of 2.</li>
<li><b>-LL_size</b> <br  />
<em>default value: 8M</em> <br  />
Specifies the total size of the unified last-level (L2) cache. Must be a power of 2 and a multiple of -line_size.</li>
<li><b>-LL_assoc</b> <br  />
<em>default value: 16</em> <br  />
Specifies the associativity of the unified last-level (L2) cache. Must be a power of 2.</li>
<li><b>-LL_miss_file</b> <br  />
<em>default value: ""</em> <br  />
If non-empty, when running the cache simulator, requests that every last-level cache miss be written to a file at the specified path. Each miss is written in text format as a &lt;program counter, address&gt; pair. If this tool is linked with zlib, the file is written in gzip-compressed format. If non-empty, when running the cache miss analyzer, requests that prefetching hints based on the miss analysis be written to the specified file. Each hint is written in text format as a &lt;program counter, stride, locality level&gt; tuple.</li>
<li><b>-L0_filter</b> <br  />
<em>default value: false</em> <br  />
Filters out instruction and data hits in a 'zero-level' cache during tracing itself, shrinking the final trace to only contain instruction and data accesses that miss in this initial cache. This cache is direct-mapped with sizes equal to -L0I_size and -L0D_size. It uses virtual addresses regardless of -use_physical.</li>
<li><b>-L0I_size</b> <br  />
<em>default value: 32K</em> <br  />
Specifies the size of the 'zero-level' instruction cache for -L0_filter. Must be a power of 2 and a multiple of -line_size, unless it is set to 0, which disables instruction fetch entries from appearing in the trace.</li>
<li><b>-L0D_size</b> <br  />
<em>default value: 32K</em> <br  />
Specifies the size of the 'zero-level' data cache for -L0_filter. Must be a power of 2 and a multiple of -line_size, unless it is set to 0, which disables data entries from appearing in the trace.</li>
<li><b>-coherence</b> <br  />
<em>default value: false</em> <br  />
Writes to cache lines will invalidate other private caches that hold that line.</li>
<li><b>-use_physical</b> <br  />
<em>default value: false</em> <br  />
If available, the default virtual addresses will be translated to physical. This is not possible from user mode on all platforms. This is not supported with -offline at this time.</li>
<li><b>-virt2phys_freq</b> <br  />
<em>default value: 0</em> <br  />
This option only applies if -use_physical is enabled. The virtual to physical mapping is cached for performance reasons, yet the underlying mapping can change without notice. This option controls the frequency with which the cached value is ignored in order to re-access the actual mapping and ensure accurate results. The units are the number of memory accesses per forced access. A value of 0 uses the cached values for the entire application execution.</li>
<li><b>-cpu_scheduling</b> <br  />
<em>default value: false</em> <br  />
By default, the simulator schedules threads to simulated cores in a static round-robin fashion. This option causes the scheduler to instead use the recorded cpu that each thread executed on (at a granularity of the trace buffer size) for scheduling, mapping traced cpu's to cores and running each segment of each thread on the core that owns the recorded cpu for that segment.</li>
<li><b>-max_trace_size</b> <br  />
<em>default value: 0</em> <br  />
If non-zero, this sets a maximum size on the amount of raw trace data gathered for each thread. This is not an exact limit: it may be exceeded by the size of one internal buffer. Once reached, instrumentation continues for that thread, but no further data is recorded.</li>
<li><b>-trace_after_instrs</b> <br  />
<em>default value: 0</em> <br  />
If non-zero, this causes tracing to be suppressed until this many dynamic instruction executions are observed. At that point, regular tracing is put into place. Use -max_trace_size to set a limit on the subsequent trace length.</li>
<li><b>-exit_after_tracing</b> <br  />
<em>default value: 0</em> <br  />
If non-zero, after tracing the specified number of references, the process is exited with an exit code of 0. The reference count is approximate.</li>
<li><b>-online_instr_types</b> <br  />
<em>default value: false</em> <br  />
By default, offline traces include some information on the types of instructions, branches in particular. For online traces, this comes at a performance cost, so it is turned off by default.</li>
<li><b>-replace_policy</b> <br  />
<em>default value: LRU</em> <br  />
Specifies the replacement policy for caches. Supported policies: LRU (Least Recently Used), LFU (Least Frequently Used), FIFO (First-In-First-Out).</li>
<li><b>-data_prefetcher</b> <br  />
<em>default value: nextline</em> <br  />
Specifies the hardware data prefetcher policy. The currently supported policies are 'nextline' (fetch the subsequent cache line) and 'none' (disables hardware prefetching). The prefetcher is located between the L1D and LL caches.</li>
<li><b>-page_size</b> <br  />
<em>default value: 4K</em> <br  />
Specifies the virtual/physical page size.</li>
<li><b>-TLB_L1I_entries</b> <br  />
<em>default value: 32</em> <br  />
Specifies the number of entries in each L1 instruction TLB. Must be a power of 2.</li>
<li><b>-TLB_L1D_entries</b> <br  />
<em>default value: 32</em> <br  />
Specifies the number of entries in each L1 data TLB. Must be a power of 2.</li>
<li><b>-TLB_L1I_assoc</b> <br  />
<em>default value: 32</em> <br  />
Specifies the associativity of each L1 instruction TLB. Must be a power of 2.</li>
<li><b>-TLB_L1D_assoc</b> <br  />
<em>default value: 32</em> <br  />
Specifies the associativity of each L1 data TLB. Must be a power of 2.</li>
<li><b>-TLB_L2_entries</b> <br  />
<em>default value: 1024</em> <br  />
Specifies the number of entries in each unified L2 TLB. Must be a power of 2.</li>
<li><b>-TLB_L2_assoc</b> <br  />
<em>default value: 4</em> <br  />
Specifies the associativity of each unified L2 TLB. Must be a power of 2.</li>
<li><b>-TLB_replace_policy</b> <br  />
<em>default value: LFU</em> <br  />
Specifies the replacement policy for TLBs. Supported policies: LFU (Least Frequently Used).</li>
<li><b>-simulator_type</b> <br  />
<em>default value: cache</em> <br  />
Specifies the type of the simulator. Supported types: cache, miss_analyzer, TLB, reuse_distance, reuse_time, histogramor basic_counts.</li>
<li><b>-verbose</b> <br  />
<em>default value: 0</em> <br  />
Verbosity level for notifications.</li>
<li><b>-show_func_trace</b> <br  />
<em>default value: true</em> <br  />
In the func_trace tool, this controls whether every traced call is shown or instead only aggregate statistics are shown.</li>
<li><b>-test_mode</b> <br  />
<em>default value: false</em> <br  />
Run extra analyses for sanity checks on the trace.</li>
<li><b>-disable_optimizations</b> <br  />
<em>default value: false</em> <br  />
Disables various optimizations where information is omitted from offline trace recording when it can be reconstructed during post-processing. This is meant for testing purposes.</li>
<li><b>-dr</b> <br  />
<em>default value: ""</em> <br  />
Specifies the path of the DynamoRIO root directory.</li>
<li><b>-dr_debug</b> <br  />
<em>default value: false</em> <br  />
Requests use of the debug build of DynamoRIO rather than the release build.</li>
<li><b>-dr_ops</b> <br  />
<em>default value: ""</em> <br  />
Specifies the options to pass to DynamoRIO.</li>
<li><b>-tracer</b> <br  />
<em>default value: ""</em> <br  />
The full path to the tracer library.</li>
<li><b>-skip_refs</b> <br  />
<em>default value: 0</em> <br  />
Specifies the number of references to skip in the beginning of the application execution. These memory references are dropped instead of being simulated.</li>
<li><b>-warmup_refs</b> <br  />
<em>default value: 0</em> <br  />
Specifies the number of memory references to warm up caches before simulation. The warmup references come after the skipped references and before the simulated references. This flag is incompatible with warmup_fraction.</li>
<li><b>-warmup_fraction</b> <br  />
<em>default value: 0</em> <br  />
Specifies the fraction of last level cache blocks to be loaded such that the cache is considered to be warmed up before simulation. The warmup fraction is computed after the skipped references and before simulated references. This flag is incompatible with warmup_refs.</li>
<li><b>-sim_refs</b> <br  />
<em>default value: 8589934592G</em> <br  />
Specifies the number of memory references to simulate. The simulated references come after the skipped and warmup references, and the references following the simulated ones are dropped.</li>
<li><b>-view_syntax</b> <br  />
<em>default value: att</em> <br  />
Specifies the syntax to use when viewing disassembled offline traces.The option can be set to one of att (default), intel, dr and arm.An invalid specification falls back to the default.</li>
<li><b>-config_file</b> <br  />
<em>default value: ""</em> <br  />
The full path to the cache hierarchy configuration file.</li>
<li><b>-report_top</b> <br  />
<em>default value: 10</em> <br  />
Specifies the number of top results to be reported.</li>
<li><b>-reuse_distance_threshold</b> <br  />
<em>default value: 100</em> <br  />
Specifies the reuse distance threshold for reporting the distant repeated references. A reference is a distant repeated reference if the distance to the previous reference on the same cache line exceeds the threshold.</li>
<li><b>-reuse_distance_histogram</b> <br  />
<em>default value: false</em> <br  />
By default only the mean, median, and standard deviation of the reuse distances are reported. This option prints out the full histogram of reuse distances.</li>
<li><b>-reuse_skip_dist</b> <br  />
<em>default value: 500</em> <br  />
Specifies the distance between nodes in the skip list. For optimal performance, set this to a value close to the estimated average reuse distance of the dataset.</li>
<li><b>-reuse_verify_skip</b> <br  />
<em>default value: false</em> <br  />
Verifies every skip list-calculated reuse distance with a full list walk. This incurs significant additional overhead. This option is only available in debug builds.</li>
<li><b>-record_function</b> <br  />
<em>default value: ""</em> <br  />
Record invocations trace for the specified function(s) in the option value. Default value is empty. The value should fit this format: function_name|func_args_num (e.g., -record_function "memset|3") with an optional suffix "|noret" (e.g., -record_function "free|1|noret"). The trace would contain information for each function invocation's return address, function argument value(s), and (unless "|noret" is specified) function return value. (If multiple requested functions map to the same address and differ in whether "noret" was specified or in the number of args, the attributes from the first one requested will be used.) We only record pointer-sized arguments and return values. The trace identifies which function is involved via a numeric ID entry prior to each set of value entries. The mapping from numeric ID to library-qualified symbolic name is recorded during tracing in a file "funclist.log" whose format is described by the <a class="el" href="drmemtrace_8h.html#abc71b61ef30155adbc03800ce7597261">drmemtrace_get_funclist_path()</a> function's documentation. If the target function is in the dynamic symbol table, then the function_name should be a mangled name (e.g. "_Znwm" for "operator new", "_ZdlPv" for "operator delete"). Otherwise, the function_name should be a demangled name. Recording multiple functions can be achieved by using the separator "&amp;" (e.g., -record_function "memset|3&amp;memcpy|3"), or specifying multiple -record_function options (e.g., -record_function "memset|3" -record_function "memcpy|3"). Note that the provided function name should be unique, and not collide with existing heap functions (see -record_heap_value) if -record_heap option is enabled.</li>
<li><b>-record_heap</b> <br  />
<em>default value: false</em> <br  />
It is a convenience option to enable recording a trace for the defined heap functions in -record_heap_value. Specifying this option is equivalent to -record_function [heap_functions], where [heap_functions] is the value in -record_heap_value.</li>
<li><b>-record_heap_value</b> <br  />
<em>default value: malloc|1&amp;free|1|noret&amp;tc_malloc|1&amp;tc_free|1|noret&amp;__libc_malloc|1&amp;__libc_free|1|noret&amp;calloc|2</em> <br  />
Functions recorded by -record_heap. The option value should fit the same format required by -record_function. These functions will not be traced unless -record_heap is specified.</li>
<li><b>-record_dynsym_only</b> <br  />
<em>default value: false</em> <br  />
Symbol lookup can be expensive for large applications and libraries. This option causes the symbol lookup for -record_function and -record_heap to look in the dynamic symbol table <em>only</em>.</li>
<li><b>-record_replace_retaddr</b> <br  />
<em>default value: false</em> <br  />
Function wrapping can be expensive for large concurrent applications. This option causes the post-function control point to be located using return address replacement, which has lower overhead, but runs the risk of breaking an application that examines or changes its own return addresses in the recorded functions.</li>
<li><b>-miss_count_threshold</b> <br  />
<em>default value: 50000</em> <br  />
Specifies the minimum number of LLC misses of a load for it to be eligible for analysis in search of patterns in the miss address stream.</li>
<li><b>-miss_frac_threshold</b> <br  />
<em>default value: 0.005</em> <br  />
Specifies the minimum fraction of LLC misses of a load (from all misses) for it to be eligible for analysis in search of patterns in the miss address stream.</li>
<li><b>-confidence_threshold</b> <br  />
<em>default value: 0.75</em> <br  />
Specifies the minimum confidence to include a discovered pattern in the output results. Confidence in a discovered pattern for a load instruction is calculated as the fraction of the load's misses with the discovered pattern over all the load's misses.</li>
</ul>
<h1><a class="anchor" id="sec_drcachesim_limit"></a>
Current Limitations</h1>
<p>The <code>drcachesim</code> tool is a work in progress. We welcome contributions in these areas of missing functionality:</p>
<ul>
<li>Multi-process online application simulation on Windows (<a href="https://github.com/DynamoRIO/dynamorio/issues/1727">https://github.com/DynamoRIO/dynamorio/issues/1727</a>)</li>
<li>Offline traces do not currently accurately record instruction fetches in dynamically generated code (<a href="https://github.com/DynamoRIO/dynamorio/issues/2062">https://github.com/DynamoRIO/dynamorio/issues/2062</a>). All data references are included, but instruction fetches may be skipped. This problem is limited to offline traces.</li>
<li>If an instruction with multiple memory accesses faults on the non-final access, the trace may incorrectly contain subsequent accesses which did not actually happen (<a href="https://github.com/DynamoRIO/dynamorio/issues/3958">https://github.com/DynamoRIO/dynamorio/issues/3958</a>).</li>
<li>Online traces may skip instructions immediately prior to non-load-or-store-related kernel transfer events (<a href="https://github.com/DynamoRIO/dynamorio/issues/3937">https://github.com/DynamoRIO/dynamorio/issues/3937</a>).</li>
<li>Application phase marking is not yet implemented (<a href="https://github.com/DynamoRIO/dynamorio/issues/2478">https://github.com/DynamoRIO/dynamorio/issues/2478</a>).</li>
</ul>
<h1><a class="anchor" id="sec_drcachesim_cmp"></a>
Comparison to Other Simulators</h1>
<p><code>drcachesim</code> is one of the few simulators to support multiple processes. This feature requires an out-of-process simulator and inter-process communication. A single-process design would incur less overhead. Thus, we expect <code>drcachesim</code> to pay for its multi-process support with potentially unfavorable performance versus single-process simulators.</p>
<p>When comparing cache hits, misses, and miss rates across simulators, the details can vary substantially. For example, some other simulators (such as <code>cachegrind</code>) do not split memory references that cross cache lines into multiple hits or misses, while <code>drcachesim</code> does split them. Instructions that reference multiple memory words on the same cache line (such as <code>ldm</code> on ARM) are considered to be single accesses by <code>drcachesim</code>, while other simulators (such as <code>cachegrind</code>) may split the accesses into separate pieces. A final example involves string loop instructions on x86. <code>drcachesim</code> considers only the first iteration to involve an instruction fetch (presenting subsequent iterations as a "non-fetched instruction" which the simulator ignores: the basic_counts tool does show these as a separate statistics), while other simulators (incorrectly) issue a fetch to the instruction cache on every iteration of the string loop. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.8.16-->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer" style="float:none;text-align:center"><img border=0 src="favicon.png"> &nbsp;  DynamoRIO API version 8.0.0 --- Fri May 22 2020 13:36:07 &nbsp; <img border=0 src="favicon.png">
</small></address>
<!--END !GENERATE_TREEVIEW-->
</body>
</html>
